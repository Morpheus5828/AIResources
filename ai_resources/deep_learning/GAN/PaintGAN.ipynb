{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, BatchNormalization, ReLU, Reshape, Dense, Conv2DTranspose, LeakyReLU, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(device[0], True)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8027 files belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (512, 512, 3)\n",
    "latent_dim = 100\n",
    "batch_size = 8\n",
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../../resources/image/paintImg/all_images\",\n",
    "    label_mode=None,\n",
    "    image_size=(512, 512),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = data.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 131072)            13238272  \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 32, 32, 256)      3277056   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 64, 64, 128)      819328    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 128, 128, 64)     204864    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128, 128, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 256, 256, 32)     51232     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256, 256, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 512, 512, 16)     12816     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 512, 512, 16)      0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 512, 512, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 512, 512, 3)       1203      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,608,803\n",
      "Trainable params: 17,606,787\n",
      "Non-trainable params: 2,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(16 * 16 * 512, input_shape=(latent_dim,), activation='relu'))\n",
    "generator.add(Reshape((16, 16, 512)))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(256, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(32, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(16, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2D(3, kernel_size=5, padding='same', activation='sigmoid'))\n",
    "\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 64)      3136      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 128)     131200    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 128, 128, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 256)       524544    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 64, 64, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 512)       2097664   \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 32, 32, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 524288)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 524289    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,284,417\n",
      "Trainable params: 3,282,625\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(512, 512, 3)))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/karnikakapoor/art-by-gan?scriptVersionId=84113427&cellId=19\n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(seed)\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(seed))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "discriminator_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "generator_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "model = GAN(\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    latent_dim=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(\n",
    "    d_optimizer=discriminator_opt,\n",
    "    g_optimizer=generator_opt,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='g_loss',\n",
    "    patience=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 612/1004 [=================>............] - ETA: 3:41 - d_loss: 0.5639 - g_loss: 1.6868"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=epochs, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " # Display performances curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "g_loss = history_dict['g_loss']\n",
    "d_loss = history_dict['d_loss']\n",
    "\n",
    "epochs = range(5)\n",
    "plt.plot(epochs, d_loss, 'b', label=\"d_loss\")\n",
    "plt.plot(epochs, g_loss, 'b', label=\"g_loss\", c=\"red\")\n",
    "plt.title(\"Loss during training process\")\n",
    "plt.xlabel(\"Nb epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_img=40\n",
    "\n",
    "#A function to generate and save images\n",
    "def Potrait_Generator():\n",
    "    Generated_Paintings = []\n",
    "    seed = tf.random.normal([num_img, latent_dim])\n",
    "    generated_image = generator(seed)\n",
    "    generated_image *= 255\n",
    "    generated_image = generated_image.numpy()\n",
    "    for i in range(num_img):\n",
    "            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n",
    "            Generated_Paintings.append(img)\n",
    "            img.save(\"Potraits{:02d}.png\".format(i))\n",
    "    return\n",
    "\n",
    "#Generating images\n",
    "Images = Potrait_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
